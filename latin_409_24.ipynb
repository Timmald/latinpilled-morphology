{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b53dcf6d-b26b-4921-b30b-3782b5940cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, getopt, re\n",
    "from functools import wraps\n",
    "from glob import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1657a8-4820-4ded-9d34-362e04c83ea3",
   "metadata": {},
   "source": [
    "# Latin Data Splits and Verb Suffixing Corrections\n",
    "This project was broken up into two main parts: Creating the data splits, and editing the baseline code to more accurately predict the morphological inflections of the 什么什么什么"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc661865-c712-4d28-835c-4ee9cd5d5b7f",
   "metadata": {},
   "source": [
    "## A. Splitting the Data\n",
    "Since Latin had no splits, our group needed to manually make the train, test, and dev sets. This task alone has a lot of factors to consider to avoid artificially inflating the accuracy of our code. Additionally, we started with nearly one million lines of data, which needed to be cut down\n",
    "\n",
    "There are many factors to keep in mind while splitting the data. Below are the two main factors we focused on:\n",
    "\n",
    "#### Size of the data\n",
    "\n",
    "The size of the training data correlates with the accuracy of the code (Kodner et al. 2023). By cutting down the data, we save both on artificially raised accuracy and runtime\n",
    "\n",
    "#### Splitting-by-form vs. Splitting-by-lemma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4602276-0152-4f1c-a035-b7e9886c03fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming(s,t):\n",
    "    return sum(1 for x,y in zip(s,t) if x != y)a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c6cbf-89e2-4d2d-aa4f-58c110bc085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def halign(s,t):\n",
    "    \"\"\"Align two strings by Hamming distance.\"\"\"\n",
    "    slen = len(s)\n",
    "    tlen = len(t)\n",
    "    minscore = len(s) + len(t) + 1\n",
    "    for upad in range(0, len(t)+1):\n",
    "        upper = '_' * upad + s + (len(t) - upad) * '_'\n",
    "        lower = len(s) * '_' + t\n",
    "        score = hamming(upper, lower)\n",
    "        if score < minscore:\n",
    "            bu = upper\n",
    "            bl = lower\n",
    "            minscore = score\n",
    "\n",
    "    for lpad in range(0, len(s)+1):\n",
    "        upper = len(t) * '_' + s\n",
    "        lower = (len(s) - lpad) * '_' + t + '_' * lpad\n",
    "        score = hamming(upper, lower)\n",
    "        if score < minscore:\n",
    "            bu = upper\n",
    "            bl = lower\n",
    "            minscore = score\n",
    "\n",
    "    zipped = list(zip(bu,bl))\n",
    "    newin  = ''.join(i for i,o in zipped if i != '_' or o != '_')\n",
    "    newout = ''.join(o for i,o in zipped if i != '_' or o != '_')\n",
    "    return newin, newout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58c6f165-a221-4af7-9f5a-8d4a81170a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(s, t, inscost = 1.0, delcost = 1.0, substcost = 1.0):\n",
    "    \"\"\"Recursive implementation of Levenshtein, with alignments returned.\"\"\"\n",
    "    @memolrec\n",
    "    def lrec(spast, tpast, srem, trem, cost):\n",
    "        if len(srem) == 0:\n",
    "            return spast + len(trem) * '_', tpast + trem, '', '', cost + len(trem)\n",
    "        if len(trem) == 0:\n",
    "            return spast + srem, tpast + len(srem) * '_', '', '', cost + len(srem)\n",
    "\n",
    "        addcost = 0\n",
    "        if srem[0] != trem[0]:\n",
    "            addcost = substcost\n",
    "\n",
    "        return min((lrec(spast + srem[0], tpast + trem[0], srem[1:], trem[1:], cost + addcost),\n",
    "                   lrec(spast + '_', tpast + trem[0], srem, trem[1:], cost + inscost),\n",
    "                   lrec(spast + srem[0], tpast + '_', srem[1:], trem, cost + delcost)),\n",
    "                   key = lambda x: x[4])\n",
    "\n",
    "    answer = lrec('', '', s, t, 0)\n",
    "    return answer[0],answer[1],answer[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6382cc70-b997-4c73-ae58-b7561145c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memolrec(func):\n",
    "    \"\"\"Memoizer for Levenshtein.\"\"\"\n",
    "    cache = {}\n",
    "    @wraps(func)\n",
    "    def wrap(sp, tp, sr, tr, cost):\n",
    "        if (sr,tr) not in cache:\n",
    "            res = func(sp, tp, sr, tr, cost)\n",
    "            cache[(sr,tr)] = (res[0][len(sp):], res[1][len(tp):], res[4] - cost)\n",
    "        return sp + cache[(sr,tr)][0], tp + cache[(sr,tr)][1], '', '', cost + cache[(sr,tr)][2]\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ac44438-98a5-4bf3-9ba8-2a42e3aa2ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignprs(lemma, form):\n",
    "    \"\"\"Break lemma/form into three parts:\n",
    "    IN:  1 | 2 | 3\n",
    "    OUT: 4 | 5 | 6\n",
    "    1/4 are assumed to be prefixes, 2/5 the stem, and 3/6 a suffix.\n",
    "    1/4 and 3/6 may be empty.\n",
    "    \"\"\"\n",
    "\n",
    "    al = levenshtein(lemma, form, substcost = 1.1) # Force preference of 0:x or x:0 by 1.1 cost\n",
    "    alemma, aform = al[0], al[1]\n",
    "    # leading spaces\n",
    "    lspace = max(len(alemma) - len(alemma.lstrip('_')), len(aform) - len(aform.lstrip('_')))\n",
    "    # trailing spaces\n",
    "    tspace = max(len(alemma[::-1]) - len(alemma[::-1].lstrip('_')), len(aform[::-1]) - len(aform[::-1].lstrip('_')))\n",
    "    return alemma[0:lspace], alemma[lspace:len(alemma)-tspace], alemma[len(alemma)-tspace:], aform[0:lspace], aform[lspace:len(alemma)-tspace], aform[len(alemma)-tspace:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb568175-949d-4431-8d9d-5f6df5a8cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_suffix_rules_get(lemma, form):\n",
    "    \"\"\"Extract a number of suffix-change and prefix-change rules\n",
    "    based on a given example lemma+inflected form.\"\"\"\n",
    "    lp,lr,ls,fp,fr,fs = alignprs(lemma, form) # Get six parts, three for in three for out\n",
    "\n",
    "    # Suffix rules\n",
    "    ins  = lr + ls + \">\"\n",
    "    outs = fr + fs + \">\"\n",
    "    srules = set()\n",
    "    for i in range(min(len(ins), len(outs))):\n",
    "        srules.add((ins[i:], outs[i:]))\n",
    "    srules = {(x[0].replace('_',''), x[1].replace('_','')) for x in srules}\n",
    "\n",
    "    # Prefix rules\n",
    "    prules = set()\n",
    "    if len(lp) >= 0 or len(fp) >= 0:\n",
    "        inp = \"<\" + lp\n",
    "        outp = \"<\" + fp\n",
    "        for i in range(0,len(fr)):\n",
    "            prules.add((inp + fr[:i],outp + fr[:i]))\n",
    "            prules = {(x[0].replace('_',''), x[1].replace('_','')) for x in prules}\n",
    "\n",
    "    return prules, srules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df571781-324c-4afc-8fa1-05446680c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_best_rule(lemma, msd, allprules, allsrules):\n",
    "    \"\"\"Applies the longest-matching suffix-changing rule given an input\n",
    "    form and the MSD. Length ties in suffix rules are broken by frequency.\n",
    "    For prefix-changing rules, only the most frequent rule is chosen.\"\"\"\n",
    "\n",
    "    bestrulelen = 0\n",
    "    base = \"<\" + lemma + \">\"\n",
    "    if msd not in allprules and msd not in allsrules:\n",
    "        return lemma # Haven't seen this inflection, so bail out\n",
    "\n",
    "    if msd in allsrules:\n",
    "        applicablerules = [(x[0],x[1],y) for x,y in allsrules[msd].items() if x[0] in base]\n",
    "        if applicablerules:\n",
    "            bestrule = max(applicablerules, key = lambda x: (len(x[0]), x[2], len(x[1])))\n",
    "            base = base.replace(bestrule[0], bestrule[1])\n",
    "\n",
    "    if msd in allprules:\n",
    "        applicablerules = [(x[0],x[1],y) for x,y in allprules[msd].items() if x[0] in base]\n",
    "        if applicablerules:\n",
    "            bestrule = max(applicablerules, key = lambda x: (x[2]))\n",
    "            base = base.replace(bestrule[0], bestrule[1])\n",
    "\n",
    "    base = base.replace('<', '')\n",
    "    base = base.replace('>', '')\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d38c11f-30b3-4bb5-8553-590b6a66ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numleadingsyms(s, symbol):\n",
    "    return len(s) - len(s.lstrip(symbol))\n",
    "\n",
    "\n",
    "def numtrailingsyms(s, symbol):\n",
    "    return len(s) - len(s.rstrip(symbol))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f016884-2cd4-466a-b156-fb2c4af728f7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
